
!git clone https://huggingface.co/spaces/bilalhf/Gaia-agent
%cd Gaia-agent

!pip install -r requirements.txt

### build a vector database based on the metadata.jsonl
# https://python.langchain.com/docs/integrations/vectorstores/supabase/
import os
from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import SupabaseVectorStore
from supabase.client import Client, create_client


load_dotenv()
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2") #  dim=768
os.environ['SUPABASE_URL']=' '
os.environ['SUPABASE_SERVICE_KEY']=' '
os.environ['GROQ_API_KEY']=' '
os.environ['HF_TOKEN']=' '
HF_TOKEN = os.environ.get("HF_TOKEN")
api_key = os.environ.get("GROQ_API_KEY")
supabase_url = os.environ.get('SUPABASE_URL')
supabase_key = os.environ.get('SUPABASE_SERVICE_KEY')
supabase: Client = create_client(supabase_url, supabase_key)

# Load metadata.jsonl
import json
# Load the metadata.jsonl file
with open('metadata.jsonl', 'r') as jsonl_file:
    json_list = list(jsonl_file)

json_QA = []
for json_str in json_list:
    json_data = json.loads(json_str)
    json_QA.append(json_data)

# Converting a set of question–answer pairs into vector embeddings & Storing them in a Supabase-hosted vector database.
# This code takes a list of question–answer pairs (json_QA), embeds them using a Hugging Face model (all-mpnet-base-v2), and stores them in a Supabase vector 
#  database. Each record consists of:
# content: A string combining the question and its final answer.
# metadata: Includes the task_id as a source identifier.
# embedding: A dense vector representation of the content, used for similarity search.
# This is useful for setting up a retrieval-augmented generation (RAG) pipeline or enabling semantic search over previously answered QA tasks.

from langchain.schema import Document
docs = []
for sample in json_QA:
    content = f"Question : {sample['Question']}\n\nFinal answer : {sample['Final answer']}"
    doc = {
        "content" : content,
        "metadata" : { # meatadata的格式必须时source键，否则会报错
            "source" : sample['task_id']
        },
        "embedding" : embeddings.embed_query(content),
    }
    docs.append(doc)

# upload the documents to the vector database
try:
    response = (
        supabase.table("documents")
        .insert(docs)
        .execute()
    )
except Exception as exception:
    print("Error inserting data into Supabase:", exception)

# This initializes a Supabase-backed vector store using SupabaseVectorStore and a preloaded embedding model. It connects to the documents table in
# Supabase, which contains embedded content (like questions and answers).
# client: the authenticated Supabase client
# embedding: embedding model used to vectorize the input data
# table_name: name of the table storing vectorized documents
# query_name: Supabase SQL function used to perform similarity matching
# It then converts the vector store into a retriever object, which can be used for semantic search or retrieval-augmented generation (RAG).

vector_store = SupabaseVectorStore(
    client=supabase,
    embedding= embeddings,
    table_name="documents",
    query_name="match_documents_langchain",
)
retriever = vector_store.as_retriever()


# This code randomly selects one sample from a dataset of QA tasks (json_QA) and prints detailed metadata for manual inspection or debugging. Specifically, it 
# displays:
# Task ID, Question, and Difficulty Level
# The Final Answer provided for the task
# Annotator metadata:
# Step-by-step reasoning (Steps)
# Time taken and number of reasoning steps
# Tools used and how many
# This is helpful for understanding the structure of the dataset, validating sample formatting, or for use in building system prompts with real examples.

import random
# random.seed(42)
random_samples = random.sample(json_QA, 1)
for sample in random_samples:
    print("=" * 50)
    print(f"Task ID: {sample['task_id']}")
    print(f"Question: {sample['Question']}")
    print(f"Level: {sample['Level']}")
    print(f"Final Answer: {sample['Final answer']}")
    print(f"Annotator Metadata: ")
    print(f"  ├── Steps: ")
    for step in sample['Annotator Metadata']['Steps'].split('\n'):
        print(f"  │      ├── {step}")
    print(f"  ├── Number of steps: {sample['Annotator Metadata']['Number of steps']}")
    print(f"  ├── How long did this take?: {sample['Annotator Metadata']['How long did this take?']}")
    print(f"  ├── Tools:")
    for tool in sample['Annotator Metadata']['Tools'].split('\n'):
        print(f"  │      ├── {tool}")
    print(f"  └── Number of tools: {sample['Annotator Metadata']['Number of tools']}")
print("=" * 50)

# Querying the questions from the metadata.jsonl
from agent import generate_answer
query = "On June 6, 2023, an article by Carolyn Collins Petersen was published in Universe Today. This article mentions a team that produced a paper about their observations, linked at the bottom of the article. Find this paper. Under what NASA award number was the work performed by R. G. Arendt supported by?"
# matched_docs = vector_store.similarity_search(query, 2)
print(generate_answer(query))

# Query 2-
query="How many studio albums were published by Mercedes Sosa between 2000 and 2009(included)? You can use the latest 2022 version of english wikipedia."
print(generate_answer(query))
